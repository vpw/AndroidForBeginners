{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TSAI-END3-Ass13-main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyND/exh5WSreDJoh+CDDm3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vpw/AndroidForBeginners/blob/master/Assignment13/backup/TSAI_END3_Ass13_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dependencies"
      ],
      "metadata": {
        "id": "mNPryhWPzk3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq \"sagemaker>=2.48.0\" --upgrade\n",
        "!pip install -qq torch==1.7.1 --upgrade\n",
        "!pip install -qq sagemaker-huggingface-inference-toolkit \n",
        "!pip install -qq transformers==4.6.1 \"datasets[s3]\"\n",
        "!pip install -qq ipywidgets\n",
        "!pip install -qq watermark \n",
        "!pip install -qq \"seaborn>=0.11.0\"\n"
      ],
      "metadata": {
        "id": "lALwk9Hyta3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Development environment"
      ],
      "metadata": {
        "id": "7b35AN2xzp_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'"
      ],
      "metadata": {
        "id": "wiB_AvN3wpEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "from sagemaker.pytorch import PyTorch\n",
        "from sagemaker.debugger import ProfilerConfig, DebuggerHookConfig, Rule, ProfilerRule, rule_configs\n",
        "import sagemaker.huggingface\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "bd2K2xyFyFxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from textwrap import wrap\n",
        "\n",
        "import boto3\n",
        "import pprint\n",
        "import time\n"
      ],
      "metadata": {
        "id": "Owm9NONJyIzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "rcParams['figure.figsize'] = 17, 8\n"
      ],
      "metadata": {
        "id": "KNAKlPj7yO2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set up SageMaker session and bucket"
      ],
      "metadata": {
        "id": "BttazVEDyTpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = sagemaker.Session()\n",
        "sagemaker_session_bucket=None\n",
        "if sagemaker_session_bucket is None and sess is not None:\n",
        "    # set to default bucket if a bucket name is not given\n",
        "    sagemaker_session_bucket = sess.default_bucket()\n",
        "\n",
        "role = sagemaker.get_execution_role()\n",
        "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
        "\n",
        "print(f\"sagemaker role arn: {role}\")\n",
        "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
        "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
      ],
      "metadata": {
        "id": "CjnUNICxyVqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preparation"
      ],
      "metadata": {
        "id": "qcFnsxL6ybCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "jDCAgejjyddV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric, list_datasets, list_metrics"
      ],
      "metadata": {
        "id": "WU8qYFaCygsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = list_datasets()"
      ],
      "metadata": {
        "id": "ugsmPZ-qy2wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glue_dataset = list_datasets(with_details=True)[datasets.index('glue')]"
      ],
      "metadata": {
        "id": "cO4_4CahyrQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "actual_task = 'sst2'\n",
        "\n",
        "dataset = load_dataset(\"glue\", actual_task)\n",
        "\n",
        "metric = load_metric('glue', actual_task)"
      ],
      "metadata": {
        "id": "UWYd0fLS1UwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'glue'\n",
        "actual_task = 'sst2'\n",
        "train_dataset, test_dataset = load_dataset(dataset_name, actual_task, split=['train', 'test'])\n",
        "train_dataset = train_dataset.shuffle().select(range(10000)) # limiting the dataset size to speed up the training\n",
        "test_dataset = test_dataset.shuffle().select(range(1500))\n"
      ],
      "metadata": {
        "id": "vCX0HxND0fIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "sLyNxgNqy-g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "OjP9ui6Fyr8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "uHw2pCavzJow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_elements(dataset[\"train\"])"
      ],
      "metadata": {
        "id": "0a1K2_pxzMFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.column_names)"
      ],
      "metadata": {
        "id": "FMfCLqmpzOG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset[\"train\"]))\n",
        "print(len(dataset[\"validation\"]))\n",
        "print(len(dataset[\"test\"]))"
      ],
      "metadata": {
        "id": "_NSgRbKczQSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"].features"
      ],
      "metadata": {
        "id": "1DxTgjU9zSpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset[\"train\"].to_pandas()\n",
        "df.hist()"
      ],
      "metadata": {
        "id": "I5dG3hBJzclF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=dataset[\"train\"]['label'])\n",
        "plt.xlabel('label');"
      ],
      "metadata": {
        "id": "hq59lcqYzdeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing the dataset to be used with PyTorch\n"
      ],
      "metadata": {
        "id": "KC_w47O70Gdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_name = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "AF9g7sTQ0MJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to get the content to tokenize\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['content'], padding='max_length', truncation=True)\n",
        "\n",
        "# Tokenize\n",
        "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
        "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
        "\n",
        "# Set the format to PyTorch\n",
        "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n"
      ],
      "metadata": {
        "id": "WKmaOrEe0SFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Uploading the data to S3"
      ],
      "metadata": {
        "id": "3latyeax2osx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import botocore\n",
        "from datasets.filesystems import S3FileSystem\n",
        "\n",
        "# Upload to S3\n",
        "s3 = S3FileSystem()\n",
        "s3_prefix = f'samples/datasets/{dataset_name}'\n",
        "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
        "train_dataset.save_to_disk(training_input_path,fs=s3)\n",
        "test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test'\n",
        "test_dataset.save_to_disk(test_input_path,fs=s3)\n",
        "\n",
        "print(f'Uploaded training data to {training_input_path}')\n",
        "print(f'Uploaded testing data to {test_input_path}')\n",
        "\n"
      ],
      "metadata": {
        "id": "P0WzP4oX2oOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize ./scripts/train.py"
      ],
      "metadata": {
        "id": "0JR8wCSF5MPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating an Estimator and start a training job"
      ],
      "metadata": {
        "id": "DW7Y5Hk32u3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'distilbert-base-uncased'\n",
        "import datetime\n",
        "ct = datetime.datetime.now() \n",
        "current_time = str(ct.now()).replace(\":\", \"-\").replace(\" \", \"-\")[:19]\n",
        "training_job_name=f'finetune-{model_name}-{current_time}'\n",
        "print( training_job_name )\n"
      ],
      "metadata": {
        "id": "mJlag7t95RW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters={'epochs': 3,\n",
        "                 'train_batch_size': 32,\n",
        "                 'model_name': model_name,\n",
        "                 'tokenizer_name': tokenizer_name,\n",
        "                 'output_dir':'/opt/ml/checkpoints',\n",
        "                 }\n"
      ],
      "metadata": {
        "id": "ZJWeoff75jPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_definitions=[\n",
        "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'eval_runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
        "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]\n",
        "\n"
      ],
      "metadata": {
        "id": "_z78NPqD6fyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enable distributed data parallel with the estimator"
      ],
      "metadata": {
        "id": "Wms4tLaR783M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
        "use_spot_instances = True\n",
        "max_run = 3600\n",
        "max_wait = 3600\n"
      ],
      "metadata": {
        "id": "whhiV5M278TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rjS8Wc_68brj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
        "                            source_dir='./scripts',\n",
        "                            instance_type='ml.p3.8xlarge',\n",
        "                            instance_count=1,\n",
        "                            role=role,\n",
        "                            transformers_version='4.6', \n",
        "                            pytorch_version='1.7',\n",
        "                            py_version='py36',\n",
        "                            distribution = distribution,\n",
        "                            hyperparameters = hyperparameters,\n",
        "                            metric_definitions=metric_definitions,\n",
        "                            use_spot_instances=use_spot_instances,\n",
        "                            max_run=max_run, # expected max run in seconds,\n",
        "                            max_wait=max_wait\n",
        "                        )\n"
      ],
      "metadata": {
        "id": "4a5nZWi36nGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start training"
      ],
      "metadata": {
        "id": "HUklldY_86FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path}, wait=False, job_name=training_job_name )"
      ],
      "metadata": {
        "id": "1rM4u3Dc87yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess.wait_for_job(training_job_name)  "
      ],
      "metadata": {
        "id": "c3vKnwa_BQM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display metrics"
      ],
      "metadata": {
        "id": "JKVn0q57BkPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker import TrainingJobAnalytics\n",
        "\n",
        "# Captured metrics can be accessed as a Pandas dataframe\n",
        "df = TrainingJobAnalytics(training_job_name=training_job_name).dataframe()\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "id": "gp0Ez40XBvqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the collected metrics"
      ],
      "metadata": {
        "id": "pAcvWpaGBvQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evals = df[df.metric_name.isin(['eval_accuracy','eval_precision', 'eval_f1'])]\n",
        "losses = df[df.metric_name.isin(['loss', 'eval_loss'])]\n",
        "\n",
        "sns.lineplot(\n",
        "    x='timestamp', \n",
        "    y='value', \n",
        "    data=evals, \n",
        "    style='metric_name',\n",
        "    markers=True,\n",
        "    hue='metric_name'\n",
        ")\n",
        "\n",
        "ax2 = plt.twinx()\n",
        "sns.lineplot(\n",
        "    x='timestamp', \n",
        "    y='value', \n",
        "    data=losses, \n",
        "    hue='metric_name',\n",
        "    ax=ax2)\n"
      ],
      "metadata": {
        "id": "dVdk4yImBmCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Endpoint"
      ],
      "metadata": {
        "id": "IHQNr0v7B4UD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = huggingface_estimator.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\", endpoint_name=training_job_name)"
      ],
      "metadata": {
        "id": "KQJjE_GwCOpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "   \"inputs\": [\n",
        "       \"Good product!\",\n",
        "       \"Product is not good at all\",\n",
        "       \"Idea is good, but product quality is poor\"\n",
        "   ]\n",
        "}\n",
        "\n",
        "# request\n",
        "predictor.predict(data)"
      ],
      "metadata": {
        "id": "kwFROmaYCarp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleanup"
      ],
      "metadata": {
        "id": "NmYzBCx4CfKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.delete_endpoint()\n",
        "\n"
      ],
      "metadata": {
        "id": "FtZMm9gqCe0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}